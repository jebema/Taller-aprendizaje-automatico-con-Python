{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes neuronales con Tensorflow\n",
    "Curso: Aplicaciones del aprendizaje automático usando Python <br>\n",
    "Actividad 6: Biblioteca Tensorflow<br> <br>\n",
    "\n",
    "\n",
    "En esta actividad se utiliza la biblioteca libre para machine learning Scikit. Se utiliza la base de datos iris que contiene información de tres tipos de flores distintas. Se hace una partición de la base de datos en datos de entrenamiento, prueba, validación cruzada y se utilizan métricas para probar la eficiancia de los algoritmos.\n",
    "\n",
    "\n",
    "Este código fue obtenido del tutorial de Tensorflow \"Basic classification\" https://www.tensorflow.org/tutorials/keras/basic_classification con licencia https://creativecommons.org/licenses/by/4.0/\n",
    "\n",
    "Objetivos:\n",
    "1. Trabajar con la biblioteca Tensorflow y Keras\n",
    "2. Explorar los datos\n",
    "3. Preprocesar los datos\n",
    "4. Construir el modelo de redes neuronales\n",
    "5. Compilar el modelo\n",
    "6. Entrenar el modelo\n",
    "7. Evaluar la exactitud\n",
    "8. Hacer predicciones\n",
    "\n",
    "Dra. Jessica Beltrán Márquez <br>\n",
    "www.jessicabeltran.com.mx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trabajar con la biblioteca TensorFlor y Keras\n",
    "En este código se entrena un modelo de red neuronal para clasificar imagenes de ropa, como tenis y camisetas. \n",
    "\n",
    "Se utiliza Keras, que es una API de alto nivel para construir y entrenar modelos en TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# se importa la biblioteca Tensorflow y Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Se importa numpy para manejo de datos y matplotlib para grafica\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Se imprime la versión de tensorflow\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se importa el conjunto de datos \"Fashion\" de MNIST.\n",
    "\n",
    "Este conjunto de datos contiene 70,000 imagenes en grises en 10 categorías. Las imágenes muestran artículos de ropa individuales con una resolución de 28x28 pixeles.\n",
    "\n",
    "Um ejemplo de cómo se ven estas imágenes se muestra en la Figura 1.\n",
    "\n",
    "<img src=\"fashion-mnist-sprite.png\">\n",
    "Figura 1. Una muestra de Fashion-MNIST (por Zalando, MIT License)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se usarán 60,000 imágenes para entrenar una red neuronal, y 10,000 imágenes para evaluar que tan bien aprendió la red para clasificar imágenes. Se puede acceder al conjunto de datos Fashion MNIST directamente de TensorFlow, solo se requiere importar y cargar los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar el conjunto de datos Fashion MNIST\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "\n",
    "#Cargar el conjunto de datos, \n",
    "#Las imagenes y etiquetas que se usarán para el entrenamiento estan en (train_images, train_labels)\n",
    "#Las imagenes y etiquetas que se usarán para la prueba estan en ((test_images, test_labels)\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al cargar el conjunto de datos se regresan arreglos numpy de 28x28, con pixeles que tienen valores en un rango de 0 a 255. Las etiquetas son un arreglo de enteros, que van desde 0  a 9. Estas corresponden a las clases de la ropa que representa la imagen:\n",
    "\n",
    "| Label | Class | \n",
    "| --- | --- |\n",
    "| 0 | Blusa/Camiseta| \n",
    "| 1 | Pantalón | \n",
    "| 2 | Suéter | \n",
    "| 3 | Vestido | \n",
    "| 4 | Abrigo | \n",
    "| 5 | Sandalia | \n",
    "| 6 | Camisa | \n",
    "| 7 | Tenis | \n",
    "| 8 | Bolsa | \n",
    "| 9 | Bota | \n",
    "\n",
    "Cada imagen esta mapeada a solo una etiqueta. Ya que los nombres de las clases no estan incluidos en el conjunto de datos, hay que guardarlos en la siguiente lista para usarlas cuando se quiera identificar a las imágenes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Blusa/Camiseta', 'Pantalón', 'Suéter', 'Vestido', 'Abrigo',\n",
    "               'Sandalias', 'Camisa', 'Tenis', 'Bolsa', 'Bota']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explorar los datos\n",
    "\n",
    "Antes de entrenar el modelo, primero se explorará el formato del conjutno de datos. La siguiente función indica que hay 60,000 imágenes en los datos de entrenamiento y cada imagen se representa con 28x28 pixeles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtener la forma del arreglo numpy con las imágenes de entrenamiento\n",
    "train_images.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la misma forma, hay 60,000 etiquetas en el conjunto de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtener la cantidad de elementos en el arreglo numpy con las etiquetas de entrenamiento \n",
    "len(train_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada etiqueta es un valor entero entre 0 y 9:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mostrar el arreglo de etiquetas\n",
    "train_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay 10,000 imágenes en el conjunto de datos de prueba. De la misma forma, cada imagen se representa con 28x28 pixeles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtener la forma del arreglo numpy con las imágenes de prueba\n",
    "test_images.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la misma forma, hay 10,000 etiquetas en el conjunto de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtener la cantidad de elementos en el arreglo numpy con las etiquetas de prueba \n",
    "len(test_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesar los datos\n",
    "\n",
    "Los datos se deben preprocesar antes de entrenar la red neuronal. Si inspeccionas la primer imagen en el conjunto de datos de entrenamiento, verás que cada valor de pixel esta en el rango de 0 a 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mostrar la primer imagen\n",
    "plt.figure()\n",
    "plt.imshow(train_images[0])\n",
    "#Colocar una barra de colores que indica los valores de los pixeles\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se escalan estos valores a un rango de 0 a 1 antes de introducir los datos al modelo de la red neuronal. Para ello, se divide el valor sobre 255. Es importante que tanto el conjunto de entrenamiento como de prueba se procesen de la misma forma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se divide el conjunto de entrenamiento sobre 255\n",
    "train_images = train_images / 255.0\n",
    "#Se divide el conjunto de prueba sobre 255\n",
    "test_images = test_images / 255.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despliega las primeras 25 imágenes del conjunto de entrenamiento y despliega el nombre de la clase debajo de cada imagen. Verifica que los datos esta en una forma correcta y que estamos listo para construir y entrenar una red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    #Grafica en la subgráfica i \n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    # Grafica la imagen i\n",
    "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "    #Incluye la etitqueta de la imagen 1\n",
    "    plt.xlabel(class_names[train_labels[i]])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construir el modelo de redes neuronales\n",
    "\n",
    "Para construir la red neuronal se requiere configurar las capas del modelo y después compilar el modelo.\n",
    "\n",
    "El bloque de construcción básico de una red neuronal es la capa. Las capas extraen representaciones de los datos con los que se les administra. Estas representaciones son representativas del problema.\n",
    "\n",
    "La mayor parte del aprendizaje profundo consiste en concatenar capas simples. La mayor parte de las capas, como las de tf.keras.layers.Dense, tienen parámetros que se aprenden durante el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se definen las capas\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La primera capa en esta red, tf.keras.layers.Flatten, transforma el formato de las imagenes de un areglo 2d (de 28x28 pixeles), a un arreglo de 1d de 28x28=784 pixeles. Piensa en esta capa como un desapilamiento en renglones  de los pixeles de la imagen de forma que queden alineados. En esta capa no existe ningún parámetro por aprender ya que solo reformatea los datos.\n",
    "\n",
    "Ya que los pixeles se han aplanado, la red consiste en una secuencia de dos capas tf.keras.layers.Dense. Estas son capas  de redes neuronales densamente conectadas, o completamente conectadas. La primera capa densa tiene 128 nodos (o neuronas). La segunda (y última) capa tiene 10 nodos con softmax que regresa un arreglo con la puntiación en probabilidad de 10 elementos que suma 1. Cda nodo contiene una puntuación que indica la probabilidad que la imagen actual pertenece a una de las 10 clases.\n",
    "\n",
    "\n",
    "### Compilar el modelo\n",
    "Antes de que el modelo esté listo para el entrenamiento, necesita unos cuantos ajustes más. Estos se agregan durante la etapa de compilación del modelo.\n",
    "\n",
    "    Loss function — Indica que tan bueno es el modelo durante el entrenamiento. Queremos minimizar esta función para \"dirigir\" el modelo en la dirección correcta.\n",
    "    Optimizer — Asi es como el modelo se actualiza basado en los datos y ve como es la función loss.\n",
    "    Metrics — Se usa para monitorear los pasos de entrenamiento y de prueba. El ejemplo siguiente usa la medida exactitud, que indica la fracción de las imagenes que son clasificadas correctamente.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compilar el modelo\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenar el modelo\n",
    "\n",
    "Para entrenar un modelo de red neuronal se requieren los siguientes pasos:\n",
    "\n",
    "    Alimenta el modelo con los datos de entrenamiento de este ejemplo, es decir, con los arreglos train_images y train_labels.\n",
    "    El modelo aprende a asociar las imágenes con las etiquetas.\n",
    "    Le pedimos al modelo a hacer predicciones sobre un conjunto de datos de prueba, el de este ejemplo es el arreglo test_images. Verificamos que las predicciones concuerdan con las etiquetas del arreglo test_labels.\n",
    "\n",
    "Para empezar el entrenamiento, llamamos al método *model.fit* de forma que el modelo se ajusta a los datos de entrenamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ajuste del modelo a los datos de entrenamiento\n",
    "model.fit(train_images, train_labels, epochs=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En lo que el modelo se entrena, se despliega la pérdida (loss) y la métrica de exactitud (accuracy). Este modelo llega a una exactitud de cerca de 0.88 (o 88%) en los datos de entrenamiento.\n",
    "\n",
    "### Evaluar la exactitud\n",
    "\n",
    "Ahora, comparamos como se desempeña el modelo en los datos de prueba:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluar el modelo en los datos de prueba, la pérdida (loss) se almacena en test_loss, la exactitud en test_acc\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se observa, la exactitud en el conjunto de datos de prueba es un poco menor que la exactitud en los datos de entrenamiento. Esta brecha entre la exactitud de entrenamiento y de prueba es un ejemplo denominado sobreajuste (overfitting). Este sobreajuste sucede cuando un modelo de aprendizaje automático funciona peor en datos nuevos que en los datos de entrenamiento.\n",
    "\n",
    "### Hacer predicciones\n",
    "\n",
    "Con el modelo entrenado, podemos usarlo para hacer predicciones sobre algunas imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predecir sobre las imagenes de prueba\n",
    "predictions = model.predict(test_images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo ha predicio las etiquetas para cada imagen del conjunto de prueba y se almacena en el arreglo *predictions*. Revisemos la primera predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La predicción es un arreglo con 10 números. Estos describen la \"confianza\" del modelo de que la imagen corresponde a cada uno de los 10 distintos artículos de ropa. Podemos ver cual etiqueta tiene el valor de confianza más alto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encotrar la etiqueta con el valor más alto\n",
    "np.argmax(predictions[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, el modelo tiene más confianza de que la imagen es una bota, o class_names[9]. Podemos comparar con los valores que ya conocemos de las etiquetas del conjunto de prueba para revisar si concuerdan:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos graficar para observar las primeras 10 predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para graficar la imagen predicha\n",
    "def plot_image(i, predictions_array, true_label, img):\n",
    "  predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  \n",
    "  plt.imshow(img, cmap=plt.cm.binary)\n",
    "  \n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "    #Si hay una discrepancia entre la clase predicha y la correcta entonces el color es rojo, si todo esta correcto es azúl.\n",
    "  if predicted_label == true_label:\n",
    "    color = 'blue'\n",
    "  else:\n",
    "    color = 'red'\n",
    "  #Coloca el texto con el nombre de la clase y la confianza de predicción\n",
    "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                100*np.max(predictions_array),\n",
    "                                class_names[true_label]),\n",
    "                                color=color)\n",
    "#Función para graficar el arreglo de predicciones\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "  predictions_array, true_label = predictions_array[i], true_label[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
    "  plt.ylim([0, 1])\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "    #Si hay una discrepancia entre la clase predicha y la correcta entonces el color es rojo, si todo esta correcto es azúl.\n",
    "\n",
    "  thisplot[predicted_label].set_color('red')\n",
    "  thisplot[true_label].set_color('blue')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos la imagen 0, su prediccion y el arreglo de predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "#graficar la imagen predicha\n",
    "plot_image(i, predictions, test_labels, test_images)\n",
    "plt.subplot(1,2,2)\n",
    "#graficar el arreglo de predicciones\n",
    "plot_value_array(i, predictions,  test_labels)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 12\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "#graficar la imagen predicha\n",
    "plot_image(i, predictions, test_labels, test_images)\n",
    "plt.subplot(1,2,2)\n",
    "#graficar el arreglo de predicciones\n",
    "plot_value_array(i, predictions,  test_labels)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a graficar varias imágenes con sus predicciones. Las predicciones correctas están en azúl y las incorrectas en rojo. El número indicado da el porcentaje (de 100) para la etiqueta predicha. Note que puede estar equivocado aunque tenga mucha confianza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar las primeras X imagenes de prueba, su etiqueta predicha y la verdadera etiqueta\n",
    "# Las predicciones correctas están en azúl, las incorrectas en rojo\n",
    "num_rows = 5\n",
    "num_cols = 3\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(num_images):\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "  plot_image(i, predictions, test_labels, test_images)\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "  plot_value_array(i, predictions, test_labels)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, usamos el modelo para predecir sobre una imagen sencilla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toma una imagen del conjunto de datos de prueba\n",
    "img = test_images[0]\n",
    "\n",
    "print(img.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los modelos tf.keras se optimizan para hacer predicciones en lotes o colecciones de ejemplos de una sola vez. Asi que aunque se use una sola imagen, se necesita agregar a una lista.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrega la imagen a un lote en donde es la única imagen\n",
    "img = (np.expand_dims(img,0))\n",
    "\n",
    "print(img.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora predice la imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_single = model.predict(img)\n",
    "\n",
    "print(predictions_single)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grafica las predicciones\n",
    "plot_value_array(0, predictions_single, test_labels)\n",
    "plt.xticks(range(10), class_names, rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.predict regresa una lista de listas, una para cada imagen en el lote de datos. Toma la predicciones de la (única) imagen en el lote:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_result = np.argmax(predictions_single[0])\n",
    "print(prediction_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se mostró anteriormente, el modelo predice que es clase 9 o bota."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/tutorials/keras/basic_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
